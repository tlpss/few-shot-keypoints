{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55487bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480 640\n",
      "processed image shape: torch.Size([1, 3, 224, 224])\n",
      "13\n",
      "last hidden states shape: torch.Size([1, 257, 384])\n",
      "cls token shape: torch.Size([1, 384])\n",
      "patch features shape: torch.Size([1, 16, 16, 384])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from transformers.models.dinov2.modeling_dinov2 import Dinov2Model\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "print(image.height, image.width)  # [480, 640]\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-small')\n",
    "model = Dinov2Model.from_pretrained('facebook/dinov2-small')\n",
    "\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "print(f\"processed image shape: {inputs.pixel_values.shape}\")  # [1, 3, 224, 224]\n",
    "\n",
    "\n",
    "outputs = model(**inputs, output_hidden_states=True)\n",
    "print(len(outputs.hidden_states))\n",
    "last_hidden_states = outputs[0]\n",
    "print(f\"last hidden states shape: {last_hidden_states.shape}\")  # [1, 1 + 256, 768]\n",
    "\n",
    "num_patches_height = inputs.pixel_values.shape[2] // model.config.patch_size\n",
    "num_patches_width = inputs.pixel_values.shape[3] // model.config.patch_size\n",
    "cls_token = last_hidden_states[:, 0, :]\n",
    "patch_features = last_hidden_states[:, 1:, :].unflatten(1, (num_patches_height, num_patches_width))\n",
    "\n",
    "print(f\"cls token shape: {cls_token.shape}\")\n",
    "print(f\"patch features shape: {patch_features.shape}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d8278f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed image shape: torch.Size([1, 3, 1024, 1024])\n",
      "last hidden states shape: torch.Size([1, 5330, 384])\n",
      "cls token shape: torch.Size([1, 384])\n",
      "patch features shape: torch.Size([1, 73, 73, 384])\n",
      "patches x patch size: 1022 x 1022\n"
     ]
    }
   ],
   "source": [
    "# change the input image size \n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-small',size={\"width\": 1024, \"height\": 1024},do_center_crop=False)\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "print(f\"processed image shape: {inputs.pixel_values.shape}\")  # [1, 3, 224, 224]\n",
    "\n",
    "\n",
    "outputs = model(**inputs, output_hidden_states=True)\n",
    "last_hidden_states = outputs[0]\n",
    "print(f\"last hidden states shape: {last_hidden_states.shape}\")  # [1, 1 + 256, 768]\n",
    "\n",
    "num_patches_height = inputs.pixel_values.shape[2] // model.config.patch_size\n",
    "num_patches_width = inputs.pixel_values.shape[3] // model.config.patch_size\n",
    "cls_token = last_hidden_states[:, 0, :]\n",
    "patch_features = last_hidden_states[:, 1:, :].unflatten(1, (num_patches_height, num_patches_width))\n",
    "\n",
    "print(f\"cls token shape: {cls_token.shape}\")\n",
    "print(f\"patch features shape: {patch_features.shape}\")\n",
    "\n",
    "print(f\"patches x patch size: {num_patches_height*model.config.patch_size} x {num_patches_width*model.config.patch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03c92f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "torch.Size([1, 257, 384])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m last_hidden_states = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(last_hidden_states.shape)  \u001b[38;5;66;03m# [1, 1 + 256, 768]\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m last_hidden_states.shape == (\u001b[43mbatch_size\u001b[49m, \u001b[32m1\u001b[39m + num_patches_flat, model.config.hidden_size)\n\u001b[32m      7\u001b[39m cls_token = last_hidden_states[:, \u001b[32m0\u001b[39m, :]\n\u001b[32m      8\u001b[39m patch_features = last_hidden_states[:, \u001b[32m1\u001b[39m:, :].unflatten(\u001b[32m1\u001b[39m, (num_patches_height, num_patches_width))\n",
      "\u001b[31mNameError\u001b[39m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e853d066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.dinov2.modeling_dinov2.Dinov2Model'>\n",
      "<class 'transformers.models.dinov2.configuration_dinov2.Dinov2Config'>\n",
      "<class 'transformers.models.bit.image_processing_bit.BitImageProcessor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))\n",
    "print(type(model.config))\n",
    "print(type(processor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109ad7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitImageProcessor {\n",
      "  \"crop_size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  },\n",
      "  \"do_center_crop\": false,\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"BitImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"height\": 518,\n",
      "    \"width\": 518\n",
      "  }\n",
      "}\n",
      "\n",
      "torch.Size([1, 3, 518, 518])\n",
      "25\n",
      "torch.Size([1, 1370, 1024])\n",
      "37 37\n"
     ]
    }
   ],
   "source": [
    "# now do the same for the Dinov2-large model\n",
    "\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-large')\n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-large',size={\"height\":518,\"width\":518},do_center_crop=False)\n",
    "print(processor)\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "print(inputs.pixel_values.shape)  # [1, 3, 224, 224]\n",
    "batch_size, rgb, img_height, img_width = inputs.pixel_values.shape\n",
    "num_patches_height, num_patches_width = img_height // patch_size, img_width // patch_size\n",
    "num_patches_flat = num_patches_height * num_patches_width\n",
    "\n",
    "outputs = model(**inputs, output_hidden_states=True)\n",
    "print(len(outputs.hidden_states))\n",
    "last_hidden_states = outputs[0]\n",
    "print(last_hidden_states.shape)  # [1, 1 + 256, 768]\n",
    "assert last_hidden_states.shape == (batch_size, 1 + num_patches_flat, model.config.hidden_size)\n",
    "print(num_patches_height,num_patches_width)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
