{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "911e9a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://cvlab.postech.ac.kr/research/SPair-71k/data/SPair-71k.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9467d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airo_dataset_tools.data_parsers.coco import CocoKeypointAnnotation, CocoImage, CocoKeypointCategory, CocoKeypointsDataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3e66ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_images = []\n",
    "coco_annotations = []\n",
    "coco_categories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "01a71b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "SPAIR_ROOT = Path(\"/home/tlips/Code/few-shot-keypoints/data/SPair-71k\")\n",
    "image_dir = SPAIR_ROOT / \"JPEGImages\"\n",
    "annotation_dir = SPAIR_ROOT / \"ImageAnnotation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8660b965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1800 images in /home/tlips/Code/few-shot-keypoints/data/SPair-71k/JPEGImages\n"
     ]
    }
   ],
   "source": [
    "all_image_paths = sorted(glob.glob(str(image_dir / '**' / '*.jpg'), recursive=True))\n",
    "print(f\"Found {len(all_image_paths)} images in {image_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "40b9c8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 18 categories.\n"
     ]
    }
   ],
   "source": [
    "# for each category, find a single annotation file, get the number of keypoints and create the category.\n",
    "\n",
    "def image_path_to_annotation_path(image_path):\n",
    "    image_name = Path(image_path).stem\n",
    "    category = Path(image_path).parent.name\n",
    "    annotation_path = annotation_dir / category/ f\"{image_name}.json\"\n",
    "    return annotation_path\n",
    "processed_categories = []\n",
    "for image_path in all_image_paths:\n",
    "    category = Path(image_path).parent.name\n",
    "    annotation_path = image_path_to_annotation_path(image_path)\n",
    "    \n",
    "    if category not in processed_categories:\n",
    "        processed_categories.append(category)\n",
    "             \n",
    "        with open(annotation_path, 'r') as f:\n",
    "            annotations = json.load(f)\n",
    "        \n",
    "            n_keypoints = len(annotations['kps'].keys())\n",
    "            cat = CocoKeypointCategory(\n",
    "                supercategory=\"object\",\n",
    "                id=len(coco_categories) + 1,\n",
    "                name=category,\n",
    "                #TODO: add semantically meaningful names to each semantic keypoint type\n",
    "                keypoints=[f\"kp{i}\" for i in range(n_keypoints)],\n",
    "                skeleton=[]  # Assuming no skeleton for now\n",
    "            )\n",
    "            coco_categories.append(cat)\n",
    "print(f\"Processed {len(processed_categories)} categories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "85afb0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_id_map = {cat.name: cat.id for cat in coco_categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fc242d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all images\n",
    "def generate_coco_images_and_annotations(all_image_paths):\n",
    "    coco_images = []\n",
    "    coco_annotations = []\n",
    "    for image_path in all_image_paths:\n",
    "        category = Path(image_path).parent.name\n",
    "        annotation_path = image_path_to_annotation_path(image_path)\n",
    "        \n",
    "        with open(annotation_path, 'r') as f:\n",
    "            annotations = json.load(f)\n",
    "        \n",
    "        image_id = len(coco_images) + 1\n",
    "        coco_image = CocoImage(\n",
    "            id=image_id,\n",
    "            file_name=str(Path(image_path).relative_to(image_dir.parent)),\n",
    "            width=annotations['image_width'],\n",
    "            height=annotations['image_height'],\n",
    "        )\n",
    "        coco_images.append(coco_image)\n",
    "        \n",
    "        # add annotations\n",
    "        bbox = annotations['bndbox']\n",
    "        x1,y1,x2,y2 = bbox\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        keypoints = []\n",
    "        n_keypoints = 0\n",
    "        for kp in annotations['kps'].values():\n",
    "            if kp is None:\n",
    "                keypoints.extend([0, 0, 0])\n",
    "            else:\n",
    "                n_keypoints += 1\n",
    "                u,v = kp\n",
    "                keypoints.extend([u, v, 2])\n",
    "        \n",
    "        coco_annotation = CocoKeypointAnnotation(\n",
    "            id=len(coco_annotations) + 1,\n",
    "            image_id=image_id,\n",
    "            category_id=category_to_id_map[category],\n",
    "            keypoints=keypoints,\n",
    "            num_keypoints=n_keypoints,\n",
    "            bbox=[x1, y1, width, height],\n",
    "            area=width*height,\n",
    "        )\n",
    "        #TODO: add segmentations, but they seem to have different formats.\n",
    "        coco_annotations.append(coco_annotation)\n",
    "    return coco_images, coco_annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d3695dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all in one dataset\n",
    "coco_images, coco_annotations = generate_coco_images_and_annotations(all_image_paths)\n",
    "\n",
    "coco_dataset = CocoKeypointsDataset(\n",
    "    images=coco_images,\n",
    "    annotations=coco_annotations,\n",
    "    categories=coco_categories\n",
    ")\n",
    "\n",
    "# Save the dataset to a JSON file\n",
    "output_path = SPAIR_ROOT / \"SPAIR_coco_dataset.json\"\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(coco_dataset.model_dump(), f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "015c4664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aeroplane: {'kp0': 84, 'kp1': 71, 'kp2': 75, 'kp3': 79, 'kp4': 60, 'kp5': 55, 'kp6': 61, 'kp7': 64, 'kp8': 52, 'kp9': 56, 'kp10': 51, 'kp11': 56, 'kp12': 33, 'kp13': 38, 'kp14': 33, 'kp15': 31, 'kp16': 57, 'kp17': 58, 'kp18': 47, 'kp19': 40, 'kp20': 37, 'kp21': 27, 'kp22': 69, 'kp23': 79, 'kp24': 60, 'kp25': 0, 'kp26': 0, 'kp27': 0, 'kp28': 0, 'kp29': 0}\n",
      "bicycle: {'kp0': 80, 'kp1': 90, 'kp2': 72, 'kp3': 78, 'kp4': 75, 'kp5': 67, 'kp6': 54, 'kp7': 50, 'kp8': 70, 'kp9': 62, 'kp10': 58, 'kp11': 0, 'kp12': 0, 'kp13': 79, 'kp14': 0, 'kp15': 0, 'kp16': 0, 'kp17': 0, 'kp18': 0, 'kp19': 0, 'kp20': 0, 'kp21': 0, 'kp22': 0, 'kp23': 0, 'kp24': 0, 'kp25': 0, 'kp26': 0, 'kp27': 0, 'kp28': 0, 'kp29': 0}\n",
      "bird: {'kp0': 100, 'kp1': 7, 'kp2': 8, 'kp3': 91, 'kp4': 51, 'kp5': 46, 'kp6': 92, 'kp7': 51, 'kp8': 51, 'kp9': 68, 'kp10': 62, 'kp11': 57, 'kp12': 31, 'kp13': 30, 'kp14': 49, 'kp15': 37, 'kp16': 77, 'kp17': 0, 'kp18': 0, 'kp19': 0, 'kp20': 0, 'kp21': 0, 'kp22': 0, 'kp23': 0, 'kp24': 0, 'kp25': 0, 'kp26': 0, 'kp27': 0, 'kp28': 0, 'kp29': 0}\n",
      "boat: {'kp0': 93, 'kp1': 63, 'kp2': 66, 'kp3': 55, 'kp4': 57, 'kp5': 62, 'kp6': 64, 'kp7': 44, 'kp8': 49, 'kp9': 39, 'kp10': 43, 'kp11': 47, 'kp12': 51, 'kp13': 81, 'kp14': 0, 'kp15': 0, 'kp16': 0, 'kp17': 0, 'kp18': 0, 'kp19': 0, 'kp20': 0, 'kp21': 0, 'kp22': 0, 'kp23': 0, 'kp24': 0, 'kp25': 0, 'kp26': 0, 'kp27': 0, 'kp28': 0, 'kp29': 0}\n",
      "bottle: {'kp0': 78, 'kp1': 80, 'kp2': 85, 'kp3': 89, 'kp4': 94, 'kp5': 93, 'kp6': 91, 'kp7': 90, 'kp8': 74, 'kp9': 76, 'kp10': 0, 'kp11': 0, 'kp12': 0, 'kp13': 0, 'kp14': 0, 'kp15': 0, 'kp16': 0, 'kp17': 0, 'kp18': 0, 'kp19': 0, 'kp20': 0, 'kp21': 0, 'kp22': 0, 'kp23': 0, 'kp24': 0, 'kp25': 0, 'kp26': 0, 'kp27': 0, 'kp28': 0, 'kp29': 0}\n",
      "bus: {'kp0': 59, 'kp1': 44, 'kp2': 58, 'kp3': 56, 'kp4': 46, 'kp5': 17, 'kp6': 11, 'kp7': 13, 'kp8': 0, 'kp9': 0, 'kp10': 37, 'kp11': 46, 'kp12': 41, 'kp13': 42, 'kp14': 49, 'kp15': 36, 'kp16': 70, 'kp17': 63, 'kp18': 76, 'kp19': 71, 'kp20': 24, 'kp21': 31, 'kp22': 26, 'kp23': 32, 'kp24': 34, 'kp25': 27, 'kp26': 43, 'kp27': 37, 'kp28': 53, 'kp29': 45}\n",
      "car: {'kp0': 54, 'kp1': 47, 'kp2': 44, 'kp3': 35, 'kp4': 25, 'kp5': 22, 'kp6': 47, 'kp7': 36, 'kp8': 30, 'kp9': 20, 'kp10': 35, 'kp11': 57, 'kp12': 39, 'kp13': 43, 'kp14': 56, 'kp15': 35, 'kp16': 60, 'kp17': 53, 'kp18': 62, 'kp19': 59, 'kp20': 35, 'kp21': 42, 'kp22': 35, 'kp23': 34, 'kp24': 45, 'kp25': 29, 'kp26': 53, 'kp27': 43, 'kp28': 55, 'kp29': 54}\n",
      "cat: {'kp0': 74, 'kp1': 72, 'kp2': 97, 'kp3': 99, 'kp4': 84, 'kp5': 88, 'kp6': 81, 'kp7': 88, 'kp8': 81, 'kp9': 78, 'kp10': 78, 'kp11': 47, 'kp12': 46, 'kp13': 58, 'kp14': 51, 'kp15': 0, 'kp16': 0, 'kp17': 0, 'kp18': 0, 'kp19': 0, 'kp20': 0, 'kp21': 0, 'kp22': 0, 'kp23': 0, 'kp24': 0, 'kp25': 0, 'kp26': 0, 'kp27': 0, 'kp28': 0, 'kp29': 0}\n",
      "chair: {'kp0': 81, 'kp1': 78, 'kp2': 81, 'kp3': 72, 'kp4': 69, 'kp5': 65, 'kp6': 53, 'kp7': 60, 'kp8': 87, 'kp9': 85, 'kp10': 34, 'kp11': 34, 'kp12': 31, 'kp13': 20, 'kp14': 0, 'kp15': 0, 'kp16': 0, 'kp17': 0, 'kp18': 0, 'kp19': 0, 'kp20': 0, 'kp21': 0, 'kp22': 0, 'kp23': 0, 'kp24': 0, 'kp25': 0, 'kp26': 0, 'kp27': 0, 'kp28': 0, 'kp29': 0}\n",
      "cow: {'kp0': 54, 'kp1': 52, 'kp2': 80, 'kp3': 77, 'kp4': 67, 'kp5': 64, 'kp6': 73, 'kp7': 71, 'kp8': 76, 'kp9': 54, 'kp10': 59, 'kp11': 53, 'kp12': 50, 'kp13': 23, 'kp14': 52, 'kp15': 56, 'kp16': 56, 'kp17': 35, 'kp18': 39, 'kp19': 41, 'kp20': 39, 'kp21': 0, 'kp22': 0, 'kp23': 0, 'kp24': 0, 'kp25': 0, 'kp26': 0, 'kp27': 0, 'kp28': 0, 'kp29': 0}\n",
      "dog: {'kp0': 27, 'kp1': 24, 'kp2': 78, 'kp3': 69, 'kp4': 75, 'kp5': 66, 'kp6': 91, 'kp7': 97, 'kp8': 79, 'kp9': 75, 'kp10': 83, 'kp11': 79, 'kp12': 71, 'kp13': 50, 'kp14': 86, 'kp15': 52, 'kp16': 0, 'kp17': 0, 'kp18': 0, 'kp19': 0, 'kp20': 0, 'kp21': 0, 'kp22': 0, 'kp23': 0, 'kp24': 0, 'kp25': 0, 'kp26': 0, 'kp27': 0, 'kp28': 0, 'kp29': 0}\n",
      "horse: {'kp0': 25, 'kp1': 21, 'kp2': 84, 'kp3': 88, 'kp4': 52, 'kp5': 56, 'kp6': 55, 'kp7': 59, 'kp8': 90, 'kp9': 90, 'kp10': 65, 'kp11': 67, 'kp12': 57, 'kp13': 52, 'kp14': 41, 'kp15': 57, 'kp16': 67, 'kp17': 69, 'kp18': 47, 'kp19': 43, 'kp20': 0, 'kp21': 0, 'kp22': 0, 'kp23': 0, 'kp24': 0, 'kp25': 0, 'kp26': 0, 'kp27': 0, 'kp28': 0, 'kp29': 0}\n",
      "motorbike: {'kp0': 45, 'kp1': 37, 'kp2': 79, 'kp3': 64, 'kp4': 61, 'kp5': 35, 'kp6': 90, 'kp7': 87, 'kp8': 21, 'kp9': 28, 'kp10': 38, 'kp11': 79, 'kp12': 48, 'kp13': 0, 'kp14': 0, 'kp15': 0, 'kp16': 0, 'kp17': 0, 'kp18': 0, 'kp19': 0, 'kp20': 0, 'kp21': 0, 'kp22': 0, 'kp23': 0, 'kp24': 0, 'kp25': 0, 'kp26': 0, 'kp27': 0, 'kp28': 0, 'kp29': 0}\n",
      "person: {'kp0': 54, 'kp1': 58, 'kp2': 36, 'kp3': 49, 'kp4': 72, 'kp5': 74, 'kp6': 67, 'kp7': 70, 'kp8': 69, 'kp9': 78, 'kp10': 60, 'kp11': 64, 'kp12': 60, 'kp13': 65, 'kp14': 43, 'kp15': 50, 'kp16': 30, 'kp17': 33, 'kp18': 30, 'kp19': 30, 'kp20': 0, 'kp21': 0, 'kp22': 0, 'kp23': 0, 'kp24': 0, 'kp25': 0, 'kp26': 0, 'kp27': 0, 'kp28': 0, 'kp29': 0}\n",
      "pottedplant: {'kp0': 92, 'kp1': 41, 'kp2': 85, 'kp3': 93, 'kp4': 82, 'kp5': 75, 'kp6': 69, 'kp7': 71, 'kp8': 65, 'kp9': 0, 'kp10': 0, 'kp11': 0, 'kp12': 0, 'kp13': 0, 'kp14': 0, 'kp15': 0, 'kp16': 0, 'kp17': 0, 'kp18': 0, 'kp19': 0, 'kp20': 0, 'kp21': 0, 'kp22': 0, 'kp23': 0, 'kp24': 0, 'kp25': 0, 'kp26': 0, 'kp27': 0, 'kp28': 0, 'kp29': 0}\n",
      "sheep: {'kp0': 44, 'kp1': 46, 'kp2': 78, 'kp3': 71, 'kp4': 68, 'kp5': 60, 'kp6': 71, 'kp7': 64, 'kp8': 80, 'kp9': 37, 'kp10': 34, 'kp11': 31, 'kp12': 32, 'kp13': 23, 'kp14': 35, 'kp15': 52, 'kp16': 46, 'kp17': 44, 'kp18': 44, 'kp19': 16, 'kp20': 12, 'kp21': 0, 'kp22': 0, 'kp23': 0, 'kp24': 0, 'kp25': 0, 'kp26': 0, 'kp27': 0, 'kp28': 0, 'kp29': 0}\n",
      "train: {'kp0': 97, 'kp1': 96, 'kp2': 95, 'kp3': 92, 'kp4': 54, 'kp5': 47, 'kp6': 50, 'kp7': 41, 'kp8': 92, 'kp9': 87, 'kp10': 89, 'kp11': 83, 'kp12': 76, 'kp13': 76, 'kp14': 67, 'kp15': 71, 'kp16': 94, 'kp17': 92, 'kp18': 0, 'kp19': 0, 'kp20': 0, 'kp21': 0, 'kp22': 0, 'kp23': 0, 'kp24': 0, 'kp25': 0, 'kp26': 0, 'kp27': 0, 'kp28': 0, 'kp29': 0}\n",
      "tvmonitor: {'kp0': 77, 'kp1': 84, 'kp2': 82, 'kp3': 85, 'kp4': 87, 'kp5': 90, 'kp6': 85, 'kp7': 83, 'kp8': 83, 'kp9': 87, 'kp10': 85, 'kp11': 87, 'kp12': 90, 'kp13': 93, 'kp14': 87, 'kp15': 85, 'kp16': 0, 'kp17': 0, 'kp18': 0, 'kp19': 0, 'kp20': 0, 'kp21': 0, 'kp22': 0, 'kp23': 0, 'kp24': 0, 'kp25': 0, 'kp26': 0, 'kp27': 0, 'kp28': 0, 'kp29': 0}\n"
     ]
    }
   ],
   "source": [
    "# now for each category, find the amount of keypoints for each keypoint type (bc they all have 30 annotations some are never visible, these are dropped)\n",
    "\n",
    "category_type_amount = {}\n",
    "for category in coco_dataset.categories:\n",
    "    category_type_amount[category.name] = {}\n",
    "\n",
    "    for keypoint in category.keypoints:\n",
    "        amount = 0\n",
    "        for annotation in coco_dataset.annotations:\n",
    "            if annotation.category_id == category.id:\n",
    "                if annotation.keypoints[3*category.keypoints.index(keypoint)] > 0:\n",
    "                    amount += 1\n",
    "        category_type_amount[category.name][keypoint] = amount\n",
    "    \n",
    "\n",
    "for category, keypoints in category_type_amount.items():\n",
    "    print(f\"{category}: {keypoints}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0a1a2085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aeroplane: 25\n",
      "bicycle: 12\n",
      "bird: 17\n",
      "boat: 14\n",
      "bottle: 10\n",
      "bus: 28\n",
      "car: 30\n",
      "cat: 15\n",
      "chair: 14\n",
      "cow: 21\n",
      "dog: 16\n",
      "horse: 20\n",
      "motorbike: 13\n",
      "person: 20\n",
      "pottedplant: 9\n",
      "sheep: 21\n",
      "train: 18\n",
      "tvmonitor: 16\n"
     ]
    }
   ],
   "source": [
    "# now drop all the keypoint types for which there are 0 visible keypoints\n",
    "category_id_to_category = {category.id: category for category in coco_dataset.categories}\n",
    "\n",
    "for annotation in coco_dataset.annotations:\n",
    "    new_keypoints = []\n",
    "    for idx in range(len(category_id_to_category[annotation.category_id].keypoints)):\n",
    "        if category_type_amount[category_id_to_category[annotation.category_id].name][category_id_to_category[annotation.category_id].keypoints[idx]] > 0:\n",
    "            new_keypoints.extend(annotation.keypoints[idx*3:(idx+1)*3])\n",
    "    annotation.keypoints = new_keypoints\n",
    "\n",
    "# drop all keypoints from the categories\n",
    "for category in coco_dataset.categories:\n",
    "    new_keypoints = []\n",
    "    for keypoint in category.keypoints:\n",
    "        if category_type_amount[category.name][keypoint] > 0:\n",
    "            new_keypoints.append(keypoint)\n",
    "    category.keypoints = new_keypoints\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for category in coco_dataset.categories:\n",
    "    print(f\"{category.name}: {len(category.keypoints)}\")\n",
    "for annotation in coco_dataset.annotations:\n",
    "    # check if len(keypoitns )) == 3 x len(category)\n",
    "    assert len(annotation.keypoints) == 3*len(category_id_to_category[annotation.category_id].keypoints), f\"keypoints length {len(annotation.keypoints)} != 3*len(category.keypoints) {3*len(category_id_to_category[annotation.category_id].keypoints)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6b03d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category aeroplane has 100 images and 100 annotations.\n",
      "Category bicycle has 100 images and 100 annotations.\n",
      "Category bird has 100 images and 100 annotations.\n",
      "Category boat has 100 images and 100 annotations.\n",
      "Category bottle has 100 images and 100 annotations.\n",
      "Category bus has 100 images and 100 annotations.\n",
      "Category car has 100 images and 100 annotations.\n",
      "Category cat has 100 images and 100 annotations.\n",
      "Category chair has 100 images and 100 annotations.\n",
      "Category cow has 100 images and 100 annotations.\n",
      "Category dog has 100 images and 100 annotations.\n",
      "Category horse has 100 images and 100 annotations.\n",
      "Category motorbike has 100 images and 100 annotations.\n",
      "Category person has 100 images and 100 annotations.\n",
      "Category pottedplant has 100 images and 100 annotations.\n",
      "Category sheep has 100 images and 100 annotations.\n",
      "Category train has 100 images and 100 annotations.\n",
      "Category tvmonitor has 100 images and 100 annotations.\n"
     ]
    }
   ],
   "source": [
    "# split the images by category, and split in train/test splits\n",
    "for category in coco_categories:\n",
    "    category_images = [img for img in coco_images if category.name in img.file_name]\n",
    "    category_annotations = [ann for ann in coco_annotations if ann.category_id == category.id]\n",
    "\n",
    "    print(f\"Category {category.name} has {len(category_images)} images and {len(category_annotations)} annotations.\")\n",
    "    \n",
    "    train_ratio = 0.5\n",
    "    # shuffle the images\n",
    "    import random\n",
    "    random.seed(2025)  # For reproducibility\n",
    "    random.shuffle(category_images)\n",
    "    train_category_images = category_images[:int(len(category_images) * train_ratio)]\n",
    "    test_category_images = category_images[int(len(category_images) * train_ratio):]\n",
    "\n",
    "    train_category_annotations = [ann for ann in category_annotations if ann.image_id in [img.id for img in train_category_images]]\n",
    "    test_category_annotations = [ann for ann in category_annotations if ann.image_id in [img.id for img in test_category_images]]\n",
    " \n",
    "    # Create datasets for train and test splits\n",
    "    train_category_dataset = CocoKeypointsDataset(\n",
    "        images=train_category_images,\n",
    "        annotations=train_category_annotations,\n",
    "        categories=[category]\n",
    "    )\n",
    "    test_category_dataset = CocoKeypointsDataset(\n",
    "        images=test_category_images,\n",
    "        annotations=test_category_annotations,\n",
    "        categories=[category]\n",
    "    )\n",
    "    # Save train and test datasets to separate JSON files\n",
    "    train_output_path = SPAIR_ROOT / f\"SPAIR_coco_{category.name}_train.json\"\n",
    "    with open(train_output_path, 'w') as f:\n",
    "        json.dump(train_category_dataset.model_dump(), f)    \n",
    "    \n",
    "    test_output_path = SPAIR_ROOT / f\"SPAIR_coco_{category.name}_test.json\"\n",
    "    with open(test_output_path, 'w') as f:\n",
    "        json.dump(test_category_dataset.model_dump(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cd752e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(214) tensor(60)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(1,512)\n",
    "img = torch.randn(1,512,256,256)\n",
    "\n",
    "x = x.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "sim  =cosine_similarity(x, img,dim=1)\n",
    "\n",
    "sim.shape\n",
    "\n",
    "\n",
    "\n",
    "# find argmax of sim\n",
    "\n",
    "argmax = sim.argmax()\n",
    "\n",
    "x = torch.unravel_index(argmax, sim.shape)\n",
    "_,u,v = x\n",
    "\n",
    "print(u,v)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
